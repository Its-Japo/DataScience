{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3951f86",
   "metadata": {},
   "source": [
    "# Fundamentos de Spark y Python — Laboratorio con DataFrames (Walmart Stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1a7a1",
   "metadata": {},
   "source": [
    "**Curso:** Data Science Sección 20\n",
    "\n",
    "**Duración estimada:** 1.5–2.5 horas\n",
    "\n",
    "**Modalidad:** Individual (colaboración para dudas conceptuales permitida, entrega individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55db2a",
   "metadata": {},
   "source": [
    "## Objetivos de aprendizaje\n",
    "Al finalizar, podrá:\n",
    "1. Iniciar una **SparkSession** y trabajar con **PySpark DataFrames**.\n",
    "2. **Cargar** un CSV con encabezados e inferencia de tipos.\n",
    "3. Explorar estructura: **columnas**, **esquema** y **muestras**.\n",
    "4. Ejecutar **descriptivos** y agregaciones.\n",
    "5. Aplicar **filtros**, **transformaciones** y **creación de columnas**.\n",
    "6. Calcular medidas estadísticas (p. ej., **correlación de Pearson**).\n",
    "7. Realizar consultas **temporales** (día con máximo precio; máximos por año).\n",
    "8. Comunicar hallazgos de forma ordenada y reproducible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074eb1e",
   "metadata": {},
   "source": [
    "## Datos\n",
    "- **Archivo:** `walmart_stock.csv`\n",
    "- **Periodo:** 2012–2017\n",
    "- **Columnas típicas:** `Date`, `Open`, `High`, `Low`, `Close`, `Volume`, `Adj Close`\n",
    "\n",
    "> *Nota:* No modifique el CSV; todas las transformaciones se realizan en el notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc0d3f",
   "metadata": {},
   "source": [
    "## Requisitos previos\n",
    "- Python 3.9+ (o entorno equivalente en **Google Colab**)\n",
    "- **Apache Spark 3.x** con PySpark (o `pyspark` preinstalado en Colab)\n",
    "- Conocimientos básicos de: tipos de datos, funciones de agregación, y uso de notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc20a97",
   "metadata": {},
   "source": [
    "## Entregables\n",
    "1. **Notebook ejecutado** (`.ipynb`) con todas las celdas y salidas visibles.\n",
    "2. **Conclusiones breves** (5–10 líneas) al final del notebook con interpretaciones clave.\n",
    "3. Código **comentado** y ordenado.\n",
    "\n",
    "**Formato de entrega:** Subir `.ipynb` .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081cb891",
   "metadata": {},
   "source": [
    "## 1) Configuración del entorno\n",
    "**Opción A — Local:**\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lab Spark DF — Walmart\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark version:\", spark.version)\n",
    "```\n",
    "\n",
    "**Opción B — Colab (sugerida si no tiene Spark local):**\n",
    "```python\n",
    "!pip -q install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Lab Spark DF — Walmart\").getOrCreate()\n",
    "print(\"Spark version:\", spark.version)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393768ea",
   "metadata": {},
   "source": [
    "## 2) Tareas (complete en orden y deje **toda** la evidencia en el notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4eb815",
   "metadata": {},
   "source": [
    "### 2.1 Inicie una sesión de Spark (si no está iniciada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92570384-193d-414b-abe1-b40b6845956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Lab Spark DF — Walmart\").getOrCreate()\n",
    "\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd667b2",
   "metadata": {},
   "source": [
    "### 2.2 Cargue el archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57661cba-c17e-4027-8981-641611063cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de la columna Date: date\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('walmart_stock.csv', \n",
    "                    header=True, \n",
    "                    inferSchema=True,\n",
    "                    dateFormat='yyyy-MM-dd')\n",
    "\n",
    "print(\"Tipo de la columna Date:\", dict(df.dtypes)['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d770e5e",
   "metadata": {},
   "source": [
    "### 2.3 ¿Cuáles son los nombres de las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7285e8b5-265c-4a4c-9607-dd13ae2726cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664b5e3",
   "metadata": {},
   "source": [
    "### 2.4 Muestre el **esquema** de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65bdf922-908e-4f24-b0ac-91527ec1a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1d127",
   "metadata": {},
   "source": [
    "### 2.5 Muestre las **primeras 5 filas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37f3c68d-2831-416d-9d07-c27b58d631f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca28ee8",
   "metadata": {},
   "source": [
    "### 2.6 Descriptivos con `describe()` + interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "425a9a12-2d3b-4fdf-856f-5de06cb7adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a74347",
   "metadata": {},
   "source": [
    "Se puede observar que los datos de walmart son valores que se encuentran entre los años 2012 y 2016 siendo un total de 5 años de datos.\n",
    "\n",
    "El menor volúmen se observa que es de 10010500 y el mayor volúmen es 99994400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311e3d2e",
   "metadata": {},
   "source": [
    "### 2.7 Máximo y mínimo de `Volume`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d73db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Max_Volume|Min_Volume|\n",
      "+----------+----------+\n",
      "|  80898100|   2094900|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min, mean, year\n",
    "\n",
    "df.select(max(\"Volume\").alias(\"Max_Volume\"), \n",
    "          min(\"Volume\").alias(\"Min_Volume\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1bdcf",
   "metadata": {},
   "source": [
    "### 2.8 ¿Cuántos días tuvieron `Close < 60`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72a4eafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"Close<60\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4df27",
   "metadata": {},
   "source": [
    "### 2.9 Crée la columna `Tasa_HV = High/Volume`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0829902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|             Tasa_HV|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|8.915604778943901E-6|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|8.644477436914568E-6|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|9.351828421515645E-6|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 8.29141562102703E-6|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|7.712212102001476E-6|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|7.071764823529412E-6|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|1.015495466386981E-5|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|6.576354146362592...|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 5.90145296180676E-6|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|8.547679455011844E-6|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|8.420709512685392E-6|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|1.041448341728929...|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|8.316075414862431E-6|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|9.721183814992126E-6|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|8.029436027707578E-6|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|6.307432259386365E-6|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Tasa_HV\", df[\"High\"] / df[\"Volume\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d90513",
   "metadata": {},
   "source": [
    "### 2.10 ¿Qué porcentaje del tiempo `High > 80`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69b5e558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.14%'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{(df.filter(\"High>80\").count()/df.count() * 100):.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ee1dd",
   "metadata": {},
   "source": [
    "### 2.11 Correlación de Pearson entre `High` y `Volume` + interpretación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84a5c76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3384326061737161"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(\"High\", \"Volume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6d42b",
   "metadata": {},
   "source": [
    "Por lo que se puede observar de la correlación de pearson entre las variables \"High\" y \"Volume\" se puede observar que tienen una relación inversamente proporcional de 1:3. Esto quiere decir que cuando una variable sube una unidad, la otra variable baja 3 unidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e6d94",
   "metadata": {},
   "source": [
    "### 2.12 ¿Qué día tuvo el **precio más alto** (`High`)? Devuelva la fila completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb8a8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-----+---------+-------+---------+\n",
      "|      Date|     Open|     High|  Low|    Close| Volume|Adj Close|\n",
      "+----------+---------+---------+-----+---------+-------+---------+\n",
      "|2015-01-13|90.800003|90.970001|88.93|89.309998|8215400|83.825448|\n",
      "+----------+---------+---------+-----+---------+-------+---------+\n",
      "only showing top 1 row\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"High\", ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61337e44",
   "metadata": {},
   "source": [
    "### 2.13 **Media** de la columna `Close`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9bb18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(mean(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa741f",
   "metadata": {},
   "source": [
    "### 2.14 **Máximo `High` por año**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab7e4ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year| Max_High|\n",
      "+----+---------+\n",
      "|2012|77.599998|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2015|90.970001|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(year(\"Date\").alias(\"Year\")).agg(max(\"High\").alias(\"Max_High\")).orderBy(\"Year\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846fa50f",
   "metadata": {},
   "source": [
    "## 3) Conclusiones (5–10 líneas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdad48c",
   "metadata": {},
   "source": [
    "1. **Tendencia general**: El precio de las acciones de Walmart mostró una tendencia al alza durante el período analizado, con el precio de cierre promedio incrementándose año tras año a excepción el año 2016.\n",
    "\n",
    "2. **Correlación precio-volumen**: La correlación entre el precio máximo (High) y el volumen de transacciones resultó ser débil o negativa, indicando que los días de mayor precio no necesariamente corresponden con mayor actividad de trading.\n",
    "\n",
    "3. **Comportamiento temporal**: Los máximos anuales muestran un crecimiento sostenido, reflejando la expansión y estabilidad de Walmart como empresa durante este período.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4963c8",
   "metadata": {},
   "source": [
    "## Buenas prácticas\n",
    "- Comente bloques no triviales.\n",
    "- Nombres de variables **claros** (`df_prices`, `max_high_year`, etc.).\n",
    "- Reutilice resultados intermedios para evitar recalcular.\n",
    "- Si usa Colab, fije versiones cuando sea necesario.\n",
    "- Cierre la sesión de Spark al final si corre local: `spark.stop()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663a977",
   "metadata": {},
   "source": [
    "## Errores comunes\n",
    "- Olvidar `inferSchema=True` → todo se carga como `string`.\n",
    "- Mezclar API RDD con DataFrames sin necesidad.\n",
    "- Usar funciones de Python puras en `withColumn` (use `pyspark.sql.functions`).\n",
    "- Intentar graficar DataFrames de Spark directamente: primero **convierta** a Pandas con `.toPandas()` en subconjuntos pequeños.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d651d75",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación (100 puntos)\n",
    "**A. Preparación del ambiente** (10 pts)\n",
    "- (10) SparkSession creada sin errores; versiones y entorno claros.\n",
    "\n",
    "**B. Carga y documentación de datos** (15 pts)\n",
    "- (8) CSV cargado con `header` y `inferSchema` correctos.\n",
    "- (7) Comentarios breves sobre las columnas y supuestos.\n",
    "\n",
    "**C. Exploración básica** (10 pts)\n",
    "- (4) Lista de columnas.\n",
    "- (3) `printSchema()` bien interpretado.\n",
    "- (3) `show(5)` con observaciones puntuales.\n",
    "\n",
    "**D. Descriptivos** (10 pts)\n",
    "- (6) `describe()` ejecutado y leído correctamente.\n",
    "- (4) Al menos 2 interpretaciones numéricas.\n",
    "\n",
    "**E. Agregaciones y filtros** (10 pts)\n",
    "- (5) Máx./mín. de `Volume` correctos.\n",
    "- (5) Conteo de días con `Close < 60` correcto.\n",
    "\n",
    "**F. Ingeniería de características** (10 pts)\n",
    "- (8) Columna `Tasa_HV = High/Volume` correcta y con tipo numérico.\n",
    "- (2) Justificación breve del indicador.\n",
    "\n",
    "**G. Métricas estadísticas** (10 pts)\n",
    "- (7) Correlación `High`–`Volume` calculada.\n",
    "- (3) Interpretación del valor (signo y magnitud).\n",
    "\n",
    "**H. Consultas temporales** (10 pts)\n",
    "- (5) Día con `High` máximo identificado.\n",
    "- (5) Máximo `High` por año con agrupación y orden correctos.\n",
    "\n",
    "**I. Comunicación de resultados** (10 pts)\n",
    "- (6) Conclusiones finales claras y concisas (5–10 líneas).\n",
    "- (4) Orden, legibilidad y limpieza del notebook.\n",
    "\n",
    "**J. Estilo y calidad de código** (5 pts)\n",
    "- (5) Convenciones PEP8 razonables, nombres significativos y ausencia de código muerto.\n",
    "\n",
    "> **Total: 100 puntos**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
